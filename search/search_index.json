{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Reefer Predictive Maintenance Solution This project is to demonstrate how to perform real time analytics, like predictive maintenance of Reefer container in the shipping industry, using Reefer container metric event stream. !!! note: This project is part of the reference implementation solution to demonstrate the IBM event driven reference architecture . The runtime environment in production may look like in the following diagram: The Reefer container is a IoT device, which emits container metrics every 15 minutes via the MQTT protocol. The first component receiving those messages is Apache Nifi to transform the metrics message to a kafka event. Kafka is used as the event backbone and event sourcing so microservices, deployed on openshift, can consume and publish messages. For persistence reason, we may leverage big data type of storage like Cassandra to persist the container metrics over a longer time period. This datasource is used by the Data Scientists to do its data preparation and build training and test sets and build model. Data scientists can run Jupyter lab on OpenShift and build a model to be deployed as python microservice, consumer of kafka Reefer metrics events. The action will be to change the state of the Reefer entity via an events to the containers topic. Component view For the minimum viable demonstration the runtime components looks like in the figure below: A web app, deployed on Openshift, is running a simulator to simulate the generation of Reefer container metrics while the container is at sea or during end to end transportation. The app exposes a simple POST operation with a control object to control the simulation. Here is an example of such control.json { 'containerID': 'c100', 'simulation': 'co2sensor', 'nb_of_records': 1000, 'good_temperature': 4.4 } See this section to build and deploy the simulator web app. A curl script will do the post of this json object. See this paragraph. The metrics events are sent to the containerMetrics topic in Kafka. The predictive scoring is a consumer of such events, read one event at a time and call the model internally, then sends a new event when maintenance is required. See the note for details. The maintenance requirement is an event in the containers topic. The last element is to trace the container maintenance event, in real application, this component should trigger a business process to get human performing the maintenance. The following repository is the microservice we could use on as this component, but we have a simple consumer in the consumer folder. For the machine learning environment we can use csv file as input data or postgresql database. The environment looks like in the figure below: The simulator can run as a standalone tool to create training and test data to be saved in a remote postgresql database. We use postgresql as a service on IBM cloud. The service has credential with URL and SSL certificate. Pre-requisites to build and run this solution Start by cloning this project using the command: git clone https://github.com/ibm-cloud-architecture/refarch-reefer-ml Be sure to have Event Stream or Kafka running somewhere We recommend creating the Event Stream service using the IBM Cloud catalog , you can also read our quick article on this event stream cloud deployment. We also have deployed Event Stream on Openshift running on-premise servers following the product documentation here . The following diagram illustrates the topics configured in IBM Cloud Event Stream service: With IBM Cloud deployment use the service credentials to create new credentials to get the Kafka brokers list, the admin URL and the api key needed to authenticate the consumers or producers. For Event Streams on Openshift deployment, click to the connect to the cluster button to get the broker URL and to generate the API key: select the option to generate the key for all topics. Provision a Postgresql service Use the product documentation to provision your own service. Define service credential and use the composed url, the database name and the SSL certificate. Use the following commands to get the certificate: ibmcloud login ibmcloud cdb cacert <database deployment name> Set environment variables As part of the 12 factors practice , we externalize the end points configuration in environment variables. We are providing a script template ( scripts/setenv-tmp.sh ) to set those variables for your local development. Rename this file as setenv.sh . This file is git ignored, to do not share keys and passwords in public domain. The variables help the different code in the solition to access the Event Stream broker cluster and the Postgresql service running on IBM Cloud. Building a python development environment as docker image To avoid impacting our laptop environment (specially macbook which use python), we use a dockerfile to get the basic of python 3.7.x and the python modules like kafka, http requests, pandas, sklearn, pytest... we need to develop and test the different python code of this solution. To build your python image with all the needed libraries, use the following commands: cd docker docker build -f docker-python-tools -t ibmcase/python . To use this python environment you can use the script: startPythonEnv . If you run with Event Stream on the cloud and Postgresql on your laptopn use the LOCAL argument, use IBMCLOUD otherwise: # refarch-reefer-ml project folder ./startPythonEnv.sh IBMCLOUD Build the docker image for Jupyter notebook We are using a special version of conda to add the postgresql and kafka libraries for python so we can access postgresql or kafka from notebook. The Dockerfile may use a cert.pem file, which contains the postgres certificate so the notebook can connect to postgresql service wiith SSL connection. cd docker docker build -f docker-jupyter-tool -t ibmcase/jupyter . To run this jupyter server run: # refarch-reefer-ml project folder ./startJupyterServer.sh IBMCLOUD Project approach As a major step of developing a machine learning or analytics model, it is important to have good data. In this project we are adopting a lightweight approach to develop this minimum viable product. The activities are summarized in this diagram: We encourage you to read this article for more insight on the methodology. 1- Collect data We are using a simulator to generate data and go over the detail of how to collect data in this article . If you generate the training and test sets as file, put this .csv file under the ml/data/ folder. If you use postgresql as data source be sure to have set the POSTGRES environment variables in the setenv.sh script. 2- Define the predictive scoring model Predictive maintenance and anomaly detection are complex problems to address. We do not pretend to address those complex problems in this repository, as we focus in putting in place the end to end creation and deployment of the model. To review the problem of predictive maintenance read this article. If you want to contribute to build a better model, we are looking for contributors . To build the model and work on the data, we will use a local version of Jupyter notebook to load the logistic regression nodebook from the ml folder. We have two types of notebook Start a jupyter server using our docker image and a postgresql in IBM cloud. pwd ./startJupyterServer IBMCLOUD or LOCAL Then open a web browser to http://localhost:8888?token=<sometoken> go under work/ml folder. Open one of the model: the model_logistic_regression.ipynb to work on data set saved in the ml/data/telemetries.csv file. the model_logistic_regression-pg.ipynb to work on data saved in postgresql running on IBM Cloud. The notebooks include comments to explain how the model is done. We use logistic regression to build a binary classification (maintenance required or not), as the data are simulated, and the focus is not in the model building, but more on the end to end process. The notebook persists the trained model as a pickle file so it can be loaded by a python module or another notebook. For more information on using the Jupyter notebook, here is a product documentation . Use the model in another notebook: We can use a second notebook to test the model with one telemetry record using the pickle serialized model. The notebook is named predictMaintenance.ipynb . 3- Deploy the model We have two types of deployment: Run the model in a web app to support REST calls. Run the model in an agent, consumer of reefer telemetry events and producer of container maintenance event. The scoring folder includes an eventConsumer folder for the agent implementation and a webapp for the Flask and REST end point wrapper. In this solution we use the agent implementation. So you need to copy the generated pickle file to the eventConsumer/domain folder. 4- Deploy each service","title":"Introduction"},{"location":"#reefer-predictive-maintenance-solution","text":"This project is to demonstrate how to perform real time analytics, like predictive maintenance of Reefer container in the shipping industry, using Reefer container metric event stream. !!! note: This project is part of the reference implementation solution to demonstrate the IBM event driven reference architecture . The runtime environment in production may look like in the following diagram: The Reefer container is a IoT device, which emits container metrics every 15 minutes via the MQTT protocol. The first component receiving those messages is Apache Nifi to transform the metrics message to a kafka event. Kafka is used as the event backbone and event sourcing so microservices, deployed on openshift, can consume and publish messages. For persistence reason, we may leverage big data type of storage like Cassandra to persist the container metrics over a longer time period. This datasource is used by the Data Scientists to do its data preparation and build training and test sets and build model. Data scientists can run Jupyter lab on OpenShift and build a model to be deployed as python microservice, consumer of kafka Reefer metrics events. The action will be to change the state of the Reefer entity via an events to the containers topic.","title":"Reefer Predictive Maintenance Solution"},{"location":"#component-view","text":"For the minimum viable demonstration the runtime components looks like in the figure below: A web app, deployed on Openshift, is running a simulator to simulate the generation of Reefer container metrics while the container is at sea or during end to end transportation. The app exposes a simple POST operation with a control object to control the simulation. Here is an example of such control.json { 'containerID': 'c100', 'simulation': 'co2sensor', 'nb_of_records': 1000, 'good_temperature': 4.4 } See this section to build and deploy the simulator web app. A curl script will do the post of this json object. See this paragraph. The metrics events are sent to the containerMetrics topic in Kafka. The predictive scoring is a consumer of such events, read one event at a time and call the model internally, then sends a new event when maintenance is required. See the note for details. The maintenance requirement is an event in the containers topic. The last element is to trace the container maintenance event, in real application, this component should trigger a business process to get human performing the maintenance. The following repository is the microservice we could use on as this component, but we have a simple consumer in the consumer folder. For the machine learning environment we can use csv file as input data or postgresql database. The environment looks like in the figure below: The simulator can run as a standalone tool to create training and test data to be saved in a remote postgresql database. We use postgresql as a service on IBM cloud. The service has credential with URL and SSL certificate.","title":"Component view"},{"location":"#pre-requisites-to-build-and-run-this-solution","text":"Start by cloning this project using the command: git clone https://github.com/ibm-cloud-architecture/refarch-reefer-ml","title":"Pre-requisites to build and run this solution"},{"location":"#be-sure-to-have-event-stream-or-kafka-running-somewhere","text":"We recommend creating the Event Stream service using the IBM Cloud catalog , you can also read our quick article on this event stream cloud deployment. We also have deployed Event Stream on Openshift running on-premise servers following the product documentation here . The following diagram illustrates the topics configured in IBM Cloud Event Stream service: With IBM Cloud deployment use the service credentials to create new credentials to get the Kafka brokers list, the admin URL and the api key needed to authenticate the consumers or producers. For Event Streams on Openshift deployment, click to the connect to the cluster button to get the broker URL and to generate the API key: select the option to generate the key for all topics.","title":"Be sure to have Event Stream or Kafka running somewhere"},{"location":"#provision-a-postgresql-service","text":"Use the product documentation to provision your own service. Define service credential and use the composed url, the database name and the SSL certificate. Use the following commands to get the certificate: ibmcloud login ibmcloud cdb cacert <database deployment name>","title":"Provision a Postgresql service"},{"location":"#set-environment-variables","text":"As part of the 12 factors practice , we externalize the end points configuration in environment variables. We are providing a script template ( scripts/setenv-tmp.sh ) to set those variables for your local development. Rename this file as setenv.sh . This file is git ignored, to do not share keys and passwords in public domain. The variables help the different code in the solition to access the Event Stream broker cluster and the Postgresql service running on IBM Cloud.","title":"Set environment variables"},{"location":"#building-a-python-development-environment-as-docker-image","text":"To avoid impacting our laptop environment (specially macbook which use python), we use a dockerfile to get the basic of python 3.7.x and the python modules like kafka, http requests, pandas, sklearn, pytest... we need to develop and test the different python code of this solution. To build your python image with all the needed libraries, use the following commands: cd docker docker build -f docker-python-tools -t ibmcase/python . To use this python environment you can use the script: startPythonEnv . If you run with Event Stream on the cloud and Postgresql on your laptopn use the LOCAL argument, use IBMCLOUD otherwise: # refarch-reefer-ml project folder ./startPythonEnv.sh IBMCLOUD","title":"Building a python development environment as docker image"},{"location":"#build-the-docker-image-for-jupyter-notebook","text":"We are using a special version of conda to add the postgresql and kafka libraries for python so we can access postgresql or kafka from notebook. The Dockerfile may use a cert.pem file, which contains the postgres certificate so the notebook can connect to postgresql service wiith SSL connection. cd docker docker build -f docker-jupyter-tool -t ibmcase/jupyter . To run this jupyter server run: # refarch-reefer-ml project folder ./startJupyterServer.sh IBMCLOUD","title":"Build the docker image for Jupyter notebook"},{"location":"#project-approach","text":"As a major step of developing a machine learning or analytics model, it is important to have good data. In this project we are adopting a lightweight approach to develop this minimum viable product. The activities are summarized in this diagram: We encourage you to read this article for more insight on the methodology.","title":"Project approach"},{"location":"#1-collect-data","text":"We are using a simulator to generate data and go over the detail of how to collect data in this article . If you generate the training and test sets as file, put this .csv file under the ml/data/ folder. If you use postgresql as data source be sure to have set the POSTGRES environment variables in the setenv.sh script.","title":"1- Collect data"},{"location":"#2-define-the-predictive-scoring-model","text":"Predictive maintenance and anomaly detection are complex problems to address. We do not pretend to address those complex problems in this repository, as we focus in putting in place the end to end creation and deployment of the model. To review the problem of predictive maintenance read this article. If you want to contribute to build a better model, we are looking for contributors . To build the model and work on the data, we will use a local version of Jupyter notebook to load the logistic regression nodebook from the ml folder. We have two types of notebook Start a jupyter server using our docker image and a postgresql in IBM cloud. pwd ./startJupyterServer IBMCLOUD or LOCAL Then open a web browser to http://localhost:8888?token=<sometoken> go under work/ml folder. Open one of the model: the model_logistic_regression.ipynb to work on data set saved in the ml/data/telemetries.csv file. the model_logistic_regression-pg.ipynb to work on data saved in postgresql running on IBM Cloud. The notebooks include comments to explain how the model is done. We use logistic regression to build a binary classification (maintenance required or not), as the data are simulated, and the focus is not in the model building, but more on the end to end process. The notebook persists the trained model as a pickle file so it can be loaded by a python module or another notebook. For more information on using the Jupyter notebook, here is a product documentation . Use the model in another notebook: We can use a second notebook to test the model with one telemetry record using the pickle serialized model. The notebook is named predictMaintenance.ipynb .","title":"2- Define the predictive scoring model"},{"location":"#3-deploy-the-model","text":"We have two types of deployment: Run the model in a web app to support REST calls. Run the model in an agent, consumer of reefer telemetry events and producer of container maintenance event. The scoring folder includes an eventConsumer folder for the agent implementation and a webapp for the Flask and REST end point wrapper. In this solution we use the agent implementation. So you need to copy the generated pickle file to the eventConsumer/domain folder.","title":"3- Deploy the model"},{"location":"#4-deploy-each-service","text":"","title":"4- Deploy each service"},{"location":"build-run/","text":"The Simulator as web app This is a simple python Flask web app exposing a REST POST end point and producing Reefer metrics event to kafka. The POST operation in on the /control url. The control object, to generate 1000 events with the co2sensor simulation looks like: { 'containerID': 'c100', 'simulation': 'co2sensor', 'nb_of_records': 1000, 'good_temperature': 4.4 } Simulator: Build and run on OpentShift To deploy the code to an openshift cluster do the following: Login to the openshift cluster. oc login -u apikey -p <apikey> --server=https://... Create a project if not done already: oc new-project reefershipmentsolution --description=\"A Reefer container shipment solution\" Remember the project is mapped to a kubernestes namespace, but includes other componetns too Create an app from the source code, and use source to image build process to deploy the app. You can use a subdirectory of your source code repository by specifying a --context-dir flag. oc new-app python:latest~https://github.com/ibm-cloud-architecture/refarch-reefer-ml.git --context-dir=simulator --name reefersimulator Then to track the build progress, look at the logs of the build pod: oc logs -f bc/reefersimulator The dependencies are loaded, the build is scheduled and executed, the image is uploaded to the registry, and started. To display information about the build configuration for the application: oc describe bc/reefersimulator To trigger a remote build (run on Openshift) from local source code do the following command: oc start-build reefersimulator --from-file=. Set environment variables For Broker URLs oc set env dc/reefersimulator KAFKA_BROKERS=kafka03-prod02.messagehub.services.us-south.blu.... For apikey: oc set env dc/reefersimulator KAFKA_APIKEY=\"\" For the kafka runtime env: oc set env dc/reefersimulator KAFKA_ENV=\"IBM_CLOUD\" Get all environment variables set for a given pod: (det the pod id with oc get pod ) oc set env pod/reefersimulator-4-tq27j --list Once the build is done you should see the container up and running oc get pod reefersimulator-3-build 0/1 Completed 0 15m reefersimulator-3-jdh2v 1/1 Running 0 1m Note The first time the container start, it may crash as the environment variables like KAFKA_APIKEY is not defined. You can use the ./scripts/setenv.sh SET command to create the needed environment variable. To make it visible externally, you need to add a route for this deployment: Use Create Route button on top right, The enter a name and select the existing service Once created, the URL of the app is visible in the route list panel: Add the host name in your local /etc/hosts or be sure the hostname is defined in DNS server. Map to the IP address of the kubernetes proxy server end point. Test sending a simulation control to the POST api The script sendSimulControl.sh is used for that. ``` pwd refarch-reefer-ml cd scripts ./sendSimulControl.sh reefersimulatorroute-reefershipmentsolution.apps.green-with-envy.ocp.csplab.local co2sensor C101 ``` If you use no argument for this script, it will send co2sensor control to the service running on our openshift cluster on IBM Cloud. Looking at the logs from the pod using `oc logs reefersimulator-3-jdh2v` you can see something like: ``` \"POST /order HTTP/1.1\" 404 232 \"-\" \"curl/7.54.0\" {'containerID': 'c100', 'simulation': 'co2sensor', 'nb_of_records': 10, 'good_temperature': 4.4} Generating 10 Co2 metrics ``` We will see how those events are processed in the next section. Unit test the Simulator The test coverage is not yet great. To run them cd simulator . / startPythonEnv root @1 de81b16f940 : / # export PYTHONPATH =/ home / simulator root @1 de81b16f940 : / # cd / home / simulator root @1 de81b16f940 : / # python tests / TestSimulator . py The predictive scoring agent Applying the same pattern as the simulation webapp, we implement a kafka consumer and producer in python that calls the serialized analytical model. The code in the scoring\\eventConsumer folder. Applying a TDD approach we start by a TestScoring.py class. import unittest from domain.predictservice import PredictService class TestScoreMetric ( unittest . TestCase ): def testCreation ( self ): serv = PredictService if __name__ == '__main__' : unittest . main () Use the same python environment with docker: . / startPythonEnv root @1 de81b16f940 : / # export PYTHONPATH =/ home / scoring / eventConsumer root @1 de81b16f940 : / # cd / home / scoring / eventConsumer root @1 de81b16f940 : / home / scoring / eventConsumer # python tests / TestScoring . py Test fails, so let add the scoring service with a constructor, and load the serialized pickle model (which was copied from the ml folder). import pickle class PredictService : def __init__ ( self , filename = \"domain/model_logistic_regression.pkl\" ): self . model = pickle . load ( open ( filename , \"rb\" ), encoding = 'latin1' ) def predict ( self , metricEvent ): TESTDATA = StringIO ( metricEvent ) data = pd . read_csv ( TESTDATA , sep = \",\" ) data . columns = data . columns . to_series () . apply ( lambda x : x . strip ()) feature_cols = [ 'Temperature(celsius)' , 'Target_Temperature(celsius)' , 'Power' , 'PowerConsumption' , 'ContentType' , 'O2' , 'CO2' , 'Time_Door_Open' , 'Maintenance_Required' , 'Defrost_Cycle' ] X = data [ feature_cols ] return self . model . predict ( X ) Next we need to test a predict on an event formated as a csv string. The test looks like: serv = PredictService() header=\"\"\"Timestamp, ID, Temperature(celsius), Target_Temperature(celsius), Power, PowerConsumption, ContentType, O2, CO2, Time_Door_Open, Maintenance_Required, Defrost_Cycle\"\"\" event=\"2019-04-01 T16:29 Z,1813, 101, 4.291843460900875,4.4,0,10.273342381017777,3,4334.920958996634,4.9631508046318755,1,0,6\"\"\" record=header+\"\\n\"+event print(serv.predict(record)) So the scoring works, now we need to code the scoring application that will be deployed to Openshift cluster, and which acts as a consumer of container metrics events and a producer container events. The Scoring Agent code of this app is ScoringAgent.py module. It starts a consumer to get messages from Kafka. And when a message is received, it needs to do some data extraction and transformation and then use the predictive service. During the tests we have issue in the data quality, so it is always a good practice to add a validation function to assess if all the records are good. For production, this code needs to be enhanced for better error handling an reporting. Run locally Under scoring\\eventConsumer folder, set the environment variables for KAFKA using the commands export KAFKA_BROKERS=broker-3.eventstreams.cloud.ibm.com:9093,broker-1.eventstreams.cloud.ibm.com:9093,broker-0.eventstreams.cloud.ibm.com:9093,broker-5.eventstreams.cloud.ibm.com:9093,broker-2.eventstreams.cloud.ibm.com:9093,broker-4.eventstreams.cloud.ibm.com:9093 export KAFKA_APIKEY=\"\" export KAFKA_ENV=IBMCLOUD docker run -e KAFKA_BROKERS=$KAFKA_BROKERS -e KAFKA_APIKEY=$KAFKA_APIKEY -e KAFKA_ENV=$KAFKA_ENV -v $(pwd)/..:/home -ti ibmcase/python bash -c \"cd /home/scoring && export PYTHONPATH=/home && python ScoringAgent.py\" Scoring: Build and run on Openshift The first time we need to add the application to the existing project, run the following command: oc new-app python:latest~https://github.com/ibm-cloud-architecture/refarch-reefer-ml.git --context-dir=scoring/eventConsumer --name reeferpredictivescoring This command will run a source to image, build all the needed yaml files for the kubernetes deployment and start the application in a pod. It use the --context flag to define what to build and run. With this capability we can use the same github repository for different sub component. As done for simulator, the scoring service needs environment variables. We can set them using the commands oc set env dc/reeferpredictivescoring KAFKA_BROKERS=$KAFKA_BROKERS oc set env dc/reeferpredictivescoring KAFKA_ENV=$KAFKA_ENV oc set env dc/reeferpredictivescoring KAFKA_APIKEY=$KAFKA_APIKEY but we have added a script for you to do so. This script needs only to be run at the first deployment. It leverage the common setenv scripts: ../scripts/setenv.sh SET The list of running pods should show the build pods for this application: oc get pods reeferpredictivescoring-1-build 1/1 Running 0 24s To run the build again after commit code to github: oc start-build reeferpredictivescoring To see the log: oc logs reeferpredictivescoring-2-rxr6j To be able to run on Openshift, the APP_FILE environment variable has to be set to ScoringApp.py. This can be done in the environment file under the .s2i folder. The scoring service has no API exposed to the external world, so we do not need to create a Route or ingress. See the integration test section to see a demonstration of the solution end to end. Run kafka on your laptop For development purpose, you can also run kafka, zookeeper and postgresql and the solution on your laptop. For that read this readme .","title":"Build and run the solution on Openshift"},{"location":"build-run/#the-simulator-as-web-app","text":"This is a simple python Flask web app exposing a REST POST end point and producing Reefer metrics event to kafka. The POST operation in on the /control url. The control object, to generate 1000 events with the co2sensor simulation looks like: { 'containerID': 'c100', 'simulation': 'co2sensor', 'nb_of_records': 1000, 'good_temperature': 4.4 }","title":"The Simulator as web app"},{"location":"build-run/#simulator-build-and-run-on-opentshift","text":"To deploy the code to an openshift cluster do the following: Login to the openshift cluster. oc login -u apikey -p <apikey> --server=https://... Create a project if not done already: oc new-project reefershipmentsolution --description=\"A Reefer container shipment solution\" Remember the project is mapped to a kubernestes namespace, but includes other componetns too Create an app from the source code, and use source to image build process to deploy the app. You can use a subdirectory of your source code repository by specifying a --context-dir flag. oc new-app python:latest~https://github.com/ibm-cloud-architecture/refarch-reefer-ml.git --context-dir=simulator --name reefersimulator Then to track the build progress, look at the logs of the build pod: oc logs -f bc/reefersimulator The dependencies are loaded, the build is scheduled and executed, the image is uploaded to the registry, and started. To display information about the build configuration for the application: oc describe bc/reefersimulator To trigger a remote build (run on Openshift) from local source code do the following command: oc start-build reefersimulator --from-file=. Set environment variables For Broker URLs oc set env dc/reefersimulator KAFKA_BROKERS=kafka03-prod02.messagehub.services.us-south.blu.... For apikey: oc set env dc/reefersimulator KAFKA_APIKEY=\"\" For the kafka runtime env: oc set env dc/reefersimulator KAFKA_ENV=\"IBM_CLOUD\" Get all environment variables set for a given pod: (det the pod id with oc get pod ) oc set env pod/reefersimulator-4-tq27j --list Once the build is done you should see the container up and running oc get pod reefersimulator-3-build 0/1 Completed 0 15m reefersimulator-3-jdh2v 1/1 Running 0 1m Note The first time the container start, it may crash as the environment variables like KAFKA_APIKEY is not defined. You can use the ./scripts/setenv.sh SET command to create the needed environment variable. To make it visible externally, you need to add a route for this deployment: Use Create Route button on top right, The enter a name and select the existing service Once created, the URL of the app is visible in the route list panel: Add the host name in your local /etc/hosts or be sure the hostname is defined in DNS server. Map to the IP address of the kubernetes proxy server end point.","title":"Simulator: Build and run on OpentShift"},{"location":"build-run/#test-sending-a-simulation-control-to-the-post-api","text":"The script sendSimulControl.sh is used for that. ``` pwd refarch-reefer-ml cd scripts ./sendSimulControl.sh reefersimulatorroute-reefershipmentsolution.apps.green-with-envy.ocp.csplab.local co2sensor C101 ``` If you use no argument for this script, it will send co2sensor control to the service running on our openshift cluster on IBM Cloud. Looking at the logs from the pod using `oc logs reefersimulator-3-jdh2v` you can see something like: ``` \"POST /order HTTP/1.1\" 404 232 \"-\" \"curl/7.54.0\" {'containerID': 'c100', 'simulation': 'co2sensor', 'nb_of_records': 10, 'good_temperature': 4.4} Generating 10 Co2 metrics ``` We will see how those events are processed in the next section.","title":"Test sending a simulation control to the POST api"},{"location":"build-run/#unit-test-the-simulator","text":"The test coverage is not yet great. To run them cd simulator . / startPythonEnv root @1 de81b16f940 : / # export PYTHONPATH =/ home / simulator root @1 de81b16f940 : / # cd / home / simulator root @1 de81b16f940 : / # python tests / TestSimulator . py","title":"Unit test the Simulator"},{"location":"build-run/#the-predictive-scoring-agent","text":"Applying the same pattern as the simulation webapp, we implement a kafka consumer and producer in python that calls the serialized analytical model. The code in the scoring\\eventConsumer folder. Applying a TDD approach we start by a TestScoring.py class. import unittest from domain.predictservice import PredictService class TestScoreMetric ( unittest . TestCase ): def testCreation ( self ): serv = PredictService if __name__ == '__main__' : unittest . main () Use the same python environment with docker: . / startPythonEnv root @1 de81b16f940 : / # export PYTHONPATH =/ home / scoring / eventConsumer root @1 de81b16f940 : / # cd / home / scoring / eventConsumer root @1 de81b16f940 : / home / scoring / eventConsumer # python tests / TestScoring . py Test fails, so let add the scoring service with a constructor, and load the serialized pickle model (which was copied from the ml folder). import pickle class PredictService : def __init__ ( self , filename = \"domain/model_logistic_regression.pkl\" ): self . model = pickle . load ( open ( filename , \"rb\" ), encoding = 'latin1' ) def predict ( self , metricEvent ): TESTDATA = StringIO ( metricEvent ) data = pd . read_csv ( TESTDATA , sep = \",\" ) data . columns = data . columns . to_series () . apply ( lambda x : x . strip ()) feature_cols = [ 'Temperature(celsius)' , 'Target_Temperature(celsius)' , 'Power' , 'PowerConsumption' , 'ContentType' , 'O2' , 'CO2' , 'Time_Door_Open' , 'Maintenance_Required' , 'Defrost_Cycle' ] X = data [ feature_cols ] return self . model . predict ( X ) Next we need to test a predict on an event formated as a csv string. The test looks like: serv = PredictService() header=\"\"\"Timestamp, ID, Temperature(celsius), Target_Temperature(celsius), Power, PowerConsumption, ContentType, O2, CO2, Time_Door_Open, Maintenance_Required, Defrost_Cycle\"\"\" event=\"2019-04-01 T16:29 Z,1813, 101, 4.291843460900875,4.4,0,10.273342381017777,3,4334.920958996634,4.9631508046318755,1,0,6\"\"\" record=header+\"\\n\"+event print(serv.predict(record)) So the scoring works, now we need to code the scoring application that will be deployed to Openshift cluster, and which acts as a consumer of container metrics events and a producer container events. The Scoring Agent code of this app is ScoringAgent.py module. It starts a consumer to get messages from Kafka. And when a message is received, it needs to do some data extraction and transformation and then use the predictive service. During the tests we have issue in the data quality, so it is always a good practice to add a validation function to assess if all the records are good. For production, this code needs to be enhanced for better error handling an reporting.","title":"The predictive scoring agent"},{"location":"build-run/#run-locally","text":"Under scoring\\eventConsumer folder, set the environment variables for KAFKA using the commands export KAFKA_BROKERS=broker-3.eventstreams.cloud.ibm.com:9093,broker-1.eventstreams.cloud.ibm.com:9093,broker-0.eventstreams.cloud.ibm.com:9093,broker-5.eventstreams.cloud.ibm.com:9093,broker-2.eventstreams.cloud.ibm.com:9093,broker-4.eventstreams.cloud.ibm.com:9093 export KAFKA_APIKEY=\"\" export KAFKA_ENV=IBMCLOUD docker run -e KAFKA_BROKERS=$KAFKA_BROKERS -e KAFKA_APIKEY=$KAFKA_APIKEY -e KAFKA_ENV=$KAFKA_ENV -v $(pwd)/..:/home -ti ibmcase/python bash -c \"cd /home/scoring && export PYTHONPATH=/home && python ScoringAgent.py\"","title":"Run locally"},{"location":"build-run/#scoring-build-and-run-on-openshift","text":"The first time we need to add the application to the existing project, run the following command: oc new-app python:latest~https://github.com/ibm-cloud-architecture/refarch-reefer-ml.git --context-dir=scoring/eventConsumer --name reeferpredictivescoring This command will run a source to image, build all the needed yaml files for the kubernetes deployment and start the application in a pod. It use the --context flag to define what to build and run. With this capability we can use the same github repository for different sub component. As done for simulator, the scoring service needs environment variables. We can set them using the commands oc set env dc/reeferpredictivescoring KAFKA_BROKERS=$KAFKA_BROKERS oc set env dc/reeferpredictivescoring KAFKA_ENV=$KAFKA_ENV oc set env dc/reeferpredictivescoring KAFKA_APIKEY=$KAFKA_APIKEY but we have added a script for you to do so. This script needs only to be run at the first deployment. It leverage the common setenv scripts: ../scripts/setenv.sh SET The list of running pods should show the build pods for this application: oc get pods reeferpredictivescoring-1-build 1/1 Running 0 24s To run the build again after commit code to github: oc start-build reeferpredictivescoring To see the log: oc logs reeferpredictivescoring-2-rxr6j To be able to run on Openshift, the APP_FILE environment variable has to be set to ScoringApp.py. This can be done in the environment file under the .s2i folder. The scoring service has no API exposed to the external world, so we do not need to create a Route or ingress. See the integration test section to see a demonstration of the solution end to end.","title":"Scoring: Build and run on Openshift"},{"location":"build-run/#run-kafka-on-your-laptop","text":"For development purpose, you can also run kafka, zookeeper and postgresql and the solution on your laptop. For that read this readme .","title":"Run kafka on your laptop"},{"location":"collect-data/","text":"As part of the IBM AI ladder practice introduced in the Data AI reference architecture and specially the collect step, we need to get a data topology in place to get data at rest so data scientist can do their data analysis, and feature preparation. In this solution, there are two datasources: the events in the kafka topic, using the event sourcing design pattern . the database about the Reefer, the fresh products and reefer telemetries As we do not have Reefer telemetry public data available, we are using our simulator to develop such data. The figure below illustrates this data injection simulation. Also you can use the simulator to create data in csv file, so there is no need to use postgresql to develop the model. Generate data with the Reefer simulator As this is not production work, using this simulator, we should be able to get the end to end story still working from a solution point of view. In the industry, when developing new manufactored product, the engineers do not have a lot of data so they also use a mixed of real sensors with some simulators to play with sensors and test their models. The historical data need to represent failure, and represent the characteristics of a Reefer container. We can imagine it includes a lot of sensors to get interesting correlated or independant features. As of now our telemetry event structure can be seen in this avro schema . We have implemented a simulator to create those metrics to be used to build the model inside Jupiter notebook and with sklearn or tensorflow library. Start python env . / startPythonEnv IBMCLOUD or LOCAL root @03721594782f : cd / home / simulator In the Dockerfile we set the first PYTHONPATH to /home to specify where python should find the new modules. root @03721594782f :/ home # Generate power off metrics When the reefer containers lose power at some time, then restart and reloose it, it may become an issue. The simulator accepts different arguments as specified below usage reefer_simulator-tool --stype [poweroff | co2sensor | o2sensor | normal] --cid [C01 | C02 | C03 | C04] --product_id [ P01 | P02 | P03 | P04 ] --records <the number of records to generate> --file <the filename to create> --append --db The cid is for the container id. As the simulator is taking some data from internal datasource you can use only one of those values: [C01 | C02 | C03 | C04] product_id is also one of the value [ P01 | P02 | P03 | P04 ] , as the simulator will derive the target temperature and humidity level from its internal datasource: ('P01','Carrots',1,4,0.4), ('P02','Banana',2,6,0.6), ('P03','Salad',1,4,0.4), ('P04','Avocado',2,6,0.4); --db is when you want to save in a postgresql DB. In this case be sure to have set the credentials and URL in the scripts/setenv.sh script (see the scripts/setenv-tmp.sh template file) --file is to specify a csv file to write the data --append is used to append the output of this run to an existing file: It permits to accumulate different simulation in the same dataset. (Re)create a new file. It is an important step to get the header as first row. root @0372 : python simulator / reefer_simulator_tool . py -- stype poweroff -- cid C01 -- records 1000 -- product_id P02 -- file telemetries . csv append to existing file python simulator/reefer_simulator_tool.py --cid C03 --product_id P02 --records 1000 --file telemetries.csv --stype poweroff --append The results looks like: Generating 1000 poweroff metrics Timestamp ID Temperature(celsius) Target_Temperature(celsius) Power PowerConsumption ContentType O2 CO2 Time_Door_Open Maintenance_Required Defrost_Cycle 1.000000 2019-06-30 T15:43 Z 101 3.416766 4 17.698034 6.662044 1 11 1 8.735273 0 6 1.001001 2019-06-30 T15:43 Z 101 4.973630 4 3.701072 8.457314 1 13 3 5.699655 0 6 1.002002 2019-06-30 T15:43 Z 101 1.299275 4 7.629094 From the two previous commands you should have 2001 rows (one gor the header which will be used in the model creation): wc -l telemetries.csv 2001 telemetries.csv Generate Co2 sensor malfunction in same file In the same way as above the simulator can generate data for Co2 sensor malfunction using the command: python simulator/reefer_simulator_tool.py --cid C03 --product_id P02 --records 1000 --file basedata --stype co2sensor --append Note The simulator is integrated in the event producer to send real time events to kafka, as if the Reefer container was loaded with fresh goods and is travelling oversea. A consumer code can call the predictive model to assess if maintenance is required and post new event on a containers topic (this consumer code is in the scoring/eventConsumer folder). Generate O2 sensor malfunction in same file python simulator/reefer_simulator_tool.py --cid C03 --product_id P02 --records 1000 --file basedata --stype o2sensor --append Saving to Postgres The same tool can be used to save to a postgresql database. First be sure to set at least the following environment variables in the setenv.sh file POSTGRES_URL, POSTGRES_DBNAME, If you want to use psql then you need to set all POSGRES* environment variables. If you use POSTGRESQL on IBM Cloud or a deployment using SSL, you need to get the SSL certificate and put it as cert.pem under the simulator folder, or set POSTGRES_SSL_PEM to the path where to find this file. The cert.pem file needs to be in the simulator folder. Run the ReeferRepository.py tool to create the database and to add the reference data: ./startPythonEnv.sh IBMCLOUD > python simulator/infrastructure/ReeferRepository.py You should see: Once done run the simulator with the --db argument like below: python simulator/reefer_simulator_tool.py --cid C03 --product_id P02 --records 1000 --stype poweroff --db Here is an example of output: Generating records for co2 sensor issue Generating records for normal behavior Generate 2000 records for Banana container_id measurement_time product_id temperature ... vent_1 vent_2 vent_3 maintenance_required 0 C03 2019-09-27 05:16:32.015791 P02 5.023500 ... True True True 0 1 C03 2019-09-27 05:21:32.015791 P02 7.015356 ... True True True 0 2 C03 2019-09-27 05:26:32.015791 P02 6.106849 ... True True True 0 3 C03 2019-09-27 05:31:32.015791 P02 6.521214 ... True True True 0 4 C03 2019-09-27 05:36:32.015791 P02 6.704980 ... True True True 0 ... ... ... ... ... ... ... ... ... [2000 rows x 18 columns] dc2537b....databases.appdomain.cloud:32347 ibmclouddb Connect remote with ssl Done uploading telemetry records ! To verify the data loaded into the database we use psql with the following script: ./postgresql/startPsql.sh IBMCLOUD Then in the CLI: # get the list of tables ibmclouddb> \\d ibmclouddb> SELECT * FROM reefers; ibmclouddb> SELECT * FROM products; ibmclouddb> SELECT * FROM reefer_telemetries; Next step is to build the model...","title":"Collect data"},{"location":"collect-data/#generate-data-with-the-reefer-simulator","text":"As this is not production work, using this simulator, we should be able to get the end to end story still working from a solution point of view. In the industry, when developing new manufactored product, the engineers do not have a lot of data so they also use a mixed of real sensors with some simulators to play with sensors and test their models. The historical data need to represent failure, and represent the characteristics of a Reefer container. We can imagine it includes a lot of sensors to get interesting correlated or independant features. As of now our telemetry event structure can be seen in this avro schema . We have implemented a simulator to create those metrics to be used to build the model inside Jupiter notebook and with sklearn or tensorflow library.","title":"Generate data with the Reefer simulator"},{"location":"collect-data/#start-python-env","text":". / startPythonEnv IBMCLOUD or LOCAL root @03721594782f : cd / home / simulator In the Dockerfile we set the first PYTHONPATH to /home to specify where python should find the new modules. root @03721594782f :/ home #","title":"Start python env"},{"location":"collect-data/#generate-power-off-metrics","text":"When the reefer containers lose power at some time, then restart and reloose it, it may become an issue. The simulator accepts different arguments as specified below usage reefer_simulator-tool --stype [poweroff | co2sensor | o2sensor | normal] --cid [C01 | C02 | C03 | C04] --product_id [ P01 | P02 | P03 | P04 ] --records <the number of records to generate> --file <the filename to create> --append --db The cid is for the container id. As the simulator is taking some data from internal datasource you can use only one of those values: [C01 | C02 | C03 | C04] product_id is also one of the value [ P01 | P02 | P03 | P04 ] , as the simulator will derive the target temperature and humidity level from its internal datasource: ('P01','Carrots',1,4,0.4), ('P02','Banana',2,6,0.6), ('P03','Salad',1,4,0.4), ('P04','Avocado',2,6,0.4); --db is when you want to save in a postgresql DB. In this case be sure to have set the credentials and URL in the scripts/setenv.sh script (see the scripts/setenv-tmp.sh template file) --file is to specify a csv file to write the data --append is used to append the output of this run to an existing file: It permits to accumulate different simulation in the same dataset. (Re)create a new file. It is an important step to get the header as first row. root @0372 : python simulator / reefer_simulator_tool . py -- stype poweroff -- cid C01 -- records 1000 -- product_id P02 -- file telemetries . csv append to existing file python simulator/reefer_simulator_tool.py --cid C03 --product_id P02 --records 1000 --file telemetries.csv --stype poweroff --append The results looks like: Generating 1000 poweroff metrics Timestamp ID Temperature(celsius) Target_Temperature(celsius) Power PowerConsumption ContentType O2 CO2 Time_Door_Open Maintenance_Required Defrost_Cycle 1.000000 2019-06-30 T15:43 Z 101 3.416766 4 17.698034 6.662044 1 11 1 8.735273 0 6 1.001001 2019-06-30 T15:43 Z 101 4.973630 4 3.701072 8.457314 1 13 3 5.699655 0 6 1.002002 2019-06-30 T15:43 Z 101 1.299275 4 7.629094 From the two previous commands you should have 2001 rows (one gor the header which will be used in the model creation): wc -l telemetries.csv 2001 telemetries.csv","title":"Generate power off metrics"},{"location":"collect-data/#generate-co2-sensor-malfunction-in-same-file","text":"In the same way as above the simulator can generate data for Co2 sensor malfunction using the command: python simulator/reefer_simulator_tool.py --cid C03 --product_id P02 --records 1000 --file basedata --stype co2sensor --append Note The simulator is integrated in the event producer to send real time events to kafka, as if the Reefer container was loaded with fresh goods and is travelling oversea. A consumer code can call the predictive model to assess if maintenance is required and post new event on a containers topic (this consumer code is in the scoring/eventConsumer folder).","title":"Generate Co2 sensor malfunction in same file"},{"location":"collect-data/#generate-o2-sensor-malfunction-in-same-file","text":"python simulator/reefer_simulator_tool.py --cid C03 --product_id P02 --records 1000 --file basedata --stype o2sensor --append","title":"Generate O2 sensor malfunction in same file"},{"location":"collect-data/#saving-to-postgres","text":"The same tool can be used to save to a postgresql database. First be sure to set at least the following environment variables in the setenv.sh file POSTGRES_URL, POSTGRES_DBNAME, If you want to use psql then you need to set all POSGRES* environment variables. If you use POSTGRESQL on IBM Cloud or a deployment using SSL, you need to get the SSL certificate and put it as cert.pem under the simulator folder, or set POSTGRES_SSL_PEM to the path where to find this file. The cert.pem file needs to be in the simulator folder. Run the ReeferRepository.py tool to create the database and to add the reference data: ./startPythonEnv.sh IBMCLOUD > python simulator/infrastructure/ReeferRepository.py You should see: Once done run the simulator with the --db argument like below: python simulator/reefer_simulator_tool.py --cid C03 --product_id P02 --records 1000 --stype poweroff --db Here is an example of output: Generating records for co2 sensor issue Generating records for normal behavior Generate 2000 records for Banana container_id measurement_time product_id temperature ... vent_1 vent_2 vent_3 maintenance_required 0 C03 2019-09-27 05:16:32.015791 P02 5.023500 ... True True True 0 1 C03 2019-09-27 05:21:32.015791 P02 7.015356 ... True True True 0 2 C03 2019-09-27 05:26:32.015791 P02 6.106849 ... True True True 0 3 C03 2019-09-27 05:31:32.015791 P02 6.521214 ... True True True 0 4 C03 2019-09-27 05:36:32.015791 P02 6.704980 ... True True True 0 ... ... ... ... ... ... ... ... ... [2000 rows x 18 columns] dc2537b....databases.appdomain.cloud:32347 ibmclouddb Connect remote with ssl Done uploading telemetry records ! To verify the data loaded into the database we use psql with the following script: ./postgresql/startPsql.sh IBMCLOUD Then in the CLI: # get the list of tables ibmclouddb> \\d ibmclouddb> SELECT * FROM reefers; ibmclouddb> SELECT * FROM products; ibmclouddb> SELECT * FROM reefer_telemetries; Next step is to build the model...","title":"Saving to Postgres"},{"location":"integration-tests/","text":"Integration tests to proof the solution Recall that the architecture of the deployed components look like in the figure below: So the first component to start is the container consumer which consumes events from the kafka containers topic. This topic is where the microservices will post messages about a Reefer container. It is used by this microservice already: Reefer container manager . Pre-requisites Be sure to have set the environment variables in the ./scripts/setenv.sh to point to your Event Stream or Kafka deployment. You need to start four terminal windows if you run the solution locally on you laptop, and only 2 terminals if you run the solution on our deployed cluster. Note Our deployed cluster in on IBM Cloud Openshift 3.11 cluster. Start Reefer container events consumer In the consumer folder use the command: ./runContainerConsumer.sh This script starts the docker python image, we built earlier and use the ConsumeContainers.py module. Start the predictive scoring service We can run it locally or on kubernetes cluster like Openshift. Under scoring folder, use the command: ./runScoringApp.sh In the beginning of the trace log you should see the bootstrap.servers brokers list, the group.id , and api key as sasl.password . Recalls the scoring is a producer and a consumer. See the build and run on Openshift section for running on kubernetes cluster. Start the simulator web app Under the simulator folder ./runReeferSimulator.sh To build and run it on Openshift review this section . Start a simulation Under the scripts folder ./sendSimulControl.sh Validate integration tests To test your local deployment ./sendSimulControl.sh localhost:8080 poweroff or to test on our cloud based deployed solution ./sendSimulControl.sh The traces will look like these: Simulator trace The trace from the pod demonstrate the configuration and the control message received at the POST operation, and then the event generated. {'bootstrap.servers': 'broker-3-\"<hidden-part>.eventstreams.cloud.ibm.com:9093,broker-1-\"<hidden-part>.eventstreams.cloud.ibm.com:9093,broker-0-\"<hidden-part>.eventstreams.cloud.ibm.com:9093,broker-5-\"<hidden-part>.eventstreams.cloud.ibm.com:9093,broker-2-\"<hidden-part>.eventstreams.cloud.ibm.com:9093,broker-4-\"<hidden-part>.eventstreams.cloud.ibm.com:9093', 'group.id': 'ReeferMetricsSimulator', 'security.protocol': 'sasl_ssl', 'sasl.mechanisms': 'PLAIN', 'ssl.ca.location': '/etc/pki/tls/cert.pem', 'sasl.username': 'token', 'sasl.password': '<hidden-part>'} ... {'containerID': 'c101', 'simulation': 'poweroff', 'nb_of_records': 50, 'good_temperature': 4.4} Reefer contaimer metric event to send:{\"containerID\": \"c101\", \"timestamp\": 1566859800, \"type\": \"ContainerMetric\", \"payload\": \"('2019-08-26 T22:50 Z', 'c101', 2.0905792037649547, 4.4, 16.282392569138707, 6.603341673152029, 2, 16, 8.827184272293419, 6.33603138958275, 0, 5)\"} Message delivered to containerMetrics [0] Reefer contaimer metric event to send:{\"containerID\": \"c101\", \"timestamp\": 1566859860, \"type\": \"ContainerMetric\", \"payload\": \"('2019-08-26 T22:51 Z', 'c101', 2.0905792037649547, 4.4, 0, -0.04371530981778182, 2, 3, 6.295683442800409, 5.36863196753292, 0, 1)\"} Message delivered to containerMetrics [0] ... Scoring trace Container consumer trace @@@ poll next container from containers partition: [0] at offset 3 with key b'c100': value: {\"timestamp\": 1566854815, \"type\": \"ContainerMaintenance\", \"version\": \"1\", \"containerID\": \"c100\", \"payload\": {\"containerID\": \"c100\", \"type\": \"Reefer\", \"status\": \"MaintenanceNeeded\", \"Reason\": \"Predictive maintenance scoring found a risk of failure\"}}","title":"Run integration tests"},{"location":"integration-tests/#integration-tests-to-proof-the-solution","text":"Recall that the architecture of the deployed components look like in the figure below: So the first component to start is the container consumer which consumes events from the kafka containers topic. This topic is where the microservices will post messages about a Reefer container. It is used by this microservice already: Reefer container manager .","title":"Integration tests to proof the solution"},{"location":"integration-tests/#pre-requisites","text":"Be sure to have set the environment variables in the ./scripts/setenv.sh to point to your Event Stream or Kafka deployment. You need to start four terminal windows if you run the solution locally on you laptop, and only 2 terminals if you run the solution on our deployed cluster. Note Our deployed cluster in on IBM Cloud Openshift 3.11 cluster.","title":"Pre-requisites"},{"location":"integration-tests/#start-reefer-container-events-consumer","text":"In the consumer folder use the command: ./runContainerConsumer.sh This script starts the docker python image, we built earlier and use the ConsumeContainers.py module.","title":"Start Reefer container events consumer"},{"location":"integration-tests/#start-the-predictive-scoring-service","text":"We can run it locally or on kubernetes cluster like Openshift. Under scoring folder, use the command: ./runScoringApp.sh In the beginning of the trace log you should see the bootstrap.servers brokers list, the group.id , and api key as sasl.password . Recalls the scoring is a producer and a consumer. See the build and run on Openshift section for running on kubernetes cluster.","title":"Start the predictive scoring service"},{"location":"integration-tests/#start-the-simulator-web-app","text":"Under the simulator folder ./runReeferSimulator.sh To build and run it on Openshift review this section .","title":"Start the simulator web app"},{"location":"integration-tests/#start-a-simulation","text":"Under the scripts folder ./sendSimulControl.sh","title":"Start a simulation"},{"location":"integration-tests/#validate-integration-tests","text":"To test your local deployment ./sendSimulControl.sh localhost:8080 poweroff or to test on our cloud based deployed solution ./sendSimulControl.sh The traces will look like these:","title":"Validate integration tests"},{"location":"integration-tests/#simulator-trace","text":"The trace from the pod demonstrate the configuration and the control message received at the POST operation, and then the event generated. {'bootstrap.servers': 'broker-3-\"<hidden-part>.eventstreams.cloud.ibm.com:9093,broker-1-\"<hidden-part>.eventstreams.cloud.ibm.com:9093,broker-0-\"<hidden-part>.eventstreams.cloud.ibm.com:9093,broker-5-\"<hidden-part>.eventstreams.cloud.ibm.com:9093,broker-2-\"<hidden-part>.eventstreams.cloud.ibm.com:9093,broker-4-\"<hidden-part>.eventstreams.cloud.ibm.com:9093', 'group.id': 'ReeferMetricsSimulator', 'security.protocol': 'sasl_ssl', 'sasl.mechanisms': 'PLAIN', 'ssl.ca.location': '/etc/pki/tls/cert.pem', 'sasl.username': 'token', 'sasl.password': '<hidden-part>'} ... {'containerID': 'c101', 'simulation': 'poweroff', 'nb_of_records': 50, 'good_temperature': 4.4} Reefer contaimer metric event to send:{\"containerID\": \"c101\", \"timestamp\": 1566859800, \"type\": \"ContainerMetric\", \"payload\": \"('2019-08-26 T22:50 Z', 'c101', 2.0905792037649547, 4.4, 16.282392569138707, 6.603341673152029, 2, 16, 8.827184272293419, 6.33603138958275, 0, 5)\"} Message delivered to containerMetrics [0] Reefer contaimer metric event to send:{\"containerID\": \"c101\", \"timestamp\": 1566859860, \"type\": \"ContainerMetric\", \"payload\": \"('2019-08-26 T22:51 Z', 'c101', 2.0905792037649547, 4.4, 0, -0.04371530981778182, 2, 3, 6.295683442800409, 5.36863196753292, 0, 1)\"} Message delivered to containerMetrics [0] ...","title":"Simulator trace"},{"location":"integration-tests/#scoring-trace","text":"","title":"Scoring trace"},{"location":"integration-tests/#container-consumer-trace","text":"@@@ poll next container from containers partition: [0] at offset 3 with key b'c100': value: {\"timestamp\": 1566854815, \"type\": \"ContainerMaintenance\", \"version\": \"1\", \"containerID\": \"c100\", \"payload\": {\"containerID\": \"c100\", \"type\": \"Reefer\", \"status\": \"MaintenanceNeeded\", \"Reason\": \"Predictive maintenance scoring found a risk of failure\"}}","title":"Container consumer trace"},{"location":"ml-work/","text":"","title":"Ml work"},{"location":"predictive-maintenance/","text":"Reefer Container Predictive Maintenance In this section, we discuss how to build an analytic model using machine learning techniques from data coming from event store like kafka. We train the model with the help of historical data to predict whether maintenance is required for the reefer container at a certain point in time. You will learn how to simulate date for reefer, develop the predictive maintenance model, and integrate the model into an application. Introduction A reefer container is a refrigerated shipping container used to store or transport frozen or cold goods perishable items or goods that require temperature control. Reefers make an excellent, portable solution for short or long term storage and can be used to ship or truck goods over long distances as they can be plugged into the power station on ships or have it clipped on generators attached. Perishable products must be kept at a controlled temperature, from point of origin to delivery to retailer or pharmacy. The logistics industry refers to this as the \u201ccold chain\u201d and it encompasses both \u201creefers\u201d (refrigerated containers) as well as warehouses, distribution centers and the final storage or holding areas. Throughout this chain the risk of failure is ever-present, meaning there is always a possibility of cargo exceeding permissible or safe temperature levels, even if only briefly. For example, a truck might be stopped without power in desert heat, allowing temperatures in the reefer to rise. Then power is restored and the temperature in the container comes back down, but the product is damaged. When cargo with such as any of those items listed above are exposed to temperatures outside of prescribed limits it can be damaged. In some cases this is evident, such as with bananas, but in other situations, like the transport of vaccines, it may not be apparent that damage has occurred and the vaccine becomes ineffective. For some products, going over temperature, even only briefly, can reduce shelf life dramatically, incurring substantial costs when it cannot be sold. Organizations contracting to ship perishable products often specify the permissible temperature range. However, even if it is possible to show that product was exposed to conditions outside of those contracted, proving where it happened, and thus responsibility, can be much harder. Predictive maintenance problem statement If you want a good understanding of the problem space for predictive maintenance read, Yana Ageeva's article in toward data science . The success of predictive maintenance models depend on three main components: having the right data framing the problem appropriately evaluating the predictions properly From a methodology point of view the Data Scientist needs to address the following questions: What type of failure to consider and which one to predict? What kind of failure is happening? slow degradation or instantaneous failure? What could be the relation between a product characteristics and the failure? What kind of measure exist to assess the given characteristic? Which measurements correspond to good functioning and which ones correspond to failure? How often metrics are reported? What question the model should answer? What kind of output should the model give? How long in advance should the model be able to indicate that a failure will occur? What are the business impact to do not predict the failure? and predicting false negative failure? What is the expected accuracy? Reefer problem types There are multiple different potential issues that could happen to a refrigerator container. We are choosing to model the \"Sensor Malfunctions\" issue: Sensors in the refrigeration unit need to be calibrated and be continuously operational. An example of failure may come from the air sensor making inaccurate readings of temperatures, which leads to sploiled content. A potential reason may come from a faulty calibration, which can go unnoticed for a good time period. It may be difficult to know if there is an issue or not. The other common potential issues are: Fluid leaks, like engine oil, coolant liquid. The preassure sensors added to the circuit may help identify preassure lost over time. Faulty belts and hoses. Faulty calibration: A non-calibrated reefer can cool at a slower or faster rate than desired. Damaged Air Chute. Condenser Issues like broken or damaged coils, clamps or bolts missing, and leaks. Door Seals damaged. Blocked air passage: to keep the temperature homogenous inside the reefer. So the question we want to answer is: does the Reefer keep accurate temperature overtime between what is set versus what is measured? Modeling techniques The model uses the generated data from above scenarios: When the container's door is open for a longer time - this gives a false positive that maintainence is required. When sensors are malfunctioning, it records arbitrary readings. When the readings are normal. We have currently trained our model on 3000 datapoints from the three scenarios above. There are different modeling approach to tackle predictive maintenance: regression model classification to predict failure for a given time period classify anomalous behavior: classes are not known in advance. Normal operation is known. compute probability of failure over time Code execution The simulator continuosly generates container metrics, publishes it to Kafka and run the predictMaintainence.ipynb to predict if maintainence is sought at this point in time. Model description We are using Machine Learning supervised learning here. There are two types of supervised learning - 1) Classification: Predict a categorical response, 2) Regression: Predict a continuous response Linear regression Pros: 1) Fast 2) No tuning required 3) Highly interpretable 4) Well-understood Cons: 1) Unlikely to produce the best predictive accuracy 2) Presumes a linear relationship between the features and response 3) If the relationship is highly non-linear as with many scenarios, linear relationship will not effectively model the relationship and its prediction would not be accurate Naive Bayes classification Naive Bayes is a probabilistic classifier inspired by the Bayes theorem under a simple assumption which is the attributes are conditionally independent. The classification is conducted by deriving the maximum posterior which is the maximal P(Ci|X) with the above assumption applying to Bayes theorem. This assumption greatly reduces the computational cost by only counting the class distribution. Even though the assumption is not valid in most cases since the attributes are dependent, surprisingly Naive Bayes has able to perform impressively. Naive Bayes is a very simple algorithm to implement and good results have obtained in most cases. It can be easily scalable to larger datasets since it takes linear time, rather than by expensive iterative approximation as used for many other types of classifiers. Naive Bayes can suffer from a problem called the zero probability problem. When the conditional probability is zero for a particular attribute, it fails to give a valid prediction. This needs to be fixed explicitly using a Laplacian estimator. Model evaluation We are using Root Mean Squared Error (RMSE) for evaluating the model performance. Root Mean Squared Error (RMSE) is the square root of the mean of the squared errors. Classification does better here as the scenarion is more of a classification problem. References Understand Reefer container For modeling predictive maintenance we found this article from BigData Republique, on Medium, very interesting. PREDICTION OF TEMPERATURE INSIDE A REFRIGERATED CONTAINER IN THE PRESENCE OF PERISHABLE GOODS Temperature Monitoring During Transportation, Storage and Processing of Perishable Products Understanding machine learning classifiers","title":"Reefer predictive maintenance problem"},{"location":"predictive-maintenance/#reefer-container-predictive-maintenance","text":"In this section, we discuss how to build an analytic model using machine learning techniques from data coming from event store like kafka. We train the model with the help of historical data to predict whether maintenance is required for the reefer container at a certain point in time. You will learn how to simulate date for reefer, develop the predictive maintenance model, and integrate the model into an application.","title":"Reefer Container Predictive Maintenance"},{"location":"predictive-maintenance/#introduction","text":"A reefer container is a refrigerated shipping container used to store or transport frozen or cold goods perishable items or goods that require temperature control. Reefers make an excellent, portable solution for short or long term storage and can be used to ship or truck goods over long distances as they can be plugged into the power station on ships or have it clipped on generators attached. Perishable products must be kept at a controlled temperature, from point of origin to delivery to retailer or pharmacy. The logistics industry refers to this as the \u201ccold chain\u201d and it encompasses both \u201creefers\u201d (refrigerated containers) as well as warehouses, distribution centers and the final storage or holding areas. Throughout this chain the risk of failure is ever-present, meaning there is always a possibility of cargo exceeding permissible or safe temperature levels, even if only briefly. For example, a truck might be stopped without power in desert heat, allowing temperatures in the reefer to rise. Then power is restored and the temperature in the container comes back down, but the product is damaged. When cargo with such as any of those items listed above are exposed to temperatures outside of prescribed limits it can be damaged. In some cases this is evident, such as with bananas, but in other situations, like the transport of vaccines, it may not be apparent that damage has occurred and the vaccine becomes ineffective. For some products, going over temperature, even only briefly, can reduce shelf life dramatically, incurring substantial costs when it cannot be sold. Organizations contracting to ship perishable products often specify the permissible temperature range. However, even if it is possible to show that product was exposed to conditions outside of those contracted, proving where it happened, and thus responsibility, can be much harder.","title":"Introduction"},{"location":"predictive-maintenance/#predictive-maintenance-problem-statement","text":"If you want a good understanding of the problem space for predictive maintenance read, Yana Ageeva's article in toward data science . The success of predictive maintenance models depend on three main components: having the right data framing the problem appropriately evaluating the predictions properly From a methodology point of view the Data Scientist needs to address the following questions: What type of failure to consider and which one to predict? What kind of failure is happening? slow degradation or instantaneous failure? What could be the relation between a product characteristics and the failure? What kind of measure exist to assess the given characteristic? Which measurements correspond to good functioning and which ones correspond to failure? How often metrics are reported? What question the model should answer? What kind of output should the model give? How long in advance should the model be able to indicate that a failure will occur? What are the business impact to do not predict the failure? and predicting false negative failure? What is the expected accuracy?","title":"Predictive maintenance problem statement"},{"location":"predictive-maintenance/#reefer-problem-types","text":"There are multiple different potential issues that could happen to a refrigerator container. We are choosing to model the \"Sensor Malfunctions\" issue: Sensors in the refrigeration unit need to be calibrated and be continuously operational. An example of failure may come from the air sensor making inaccurate readings of temperatures, which leads to sploiled content. A potential reason may come from a faulty calibration, which can go unnoticed for a good time period. It may be difficult to know if there is an issue or not. The other common potential issues are: Fluid leaks, like engine oil, coolant liquid. The preassure sensors added to the circuit may help identify preassure lost over time. Faulty belts and hoses. Faulty calibration: A non-calibrated reefer can cool at a slower or faster rate than desired. Damaged Air Chute. Condenser Issues like broken or damaged coils, clamps or bolts missing, and leaks. Door Seals damaged. Blocked air passage: to keep the temperature homogenous inside the reefer. So the question we want to answer is: does the Reefer keep accurate temperature overtime between what is set versus what is measured?","title":"Reefer problem types"},{"location":"predictive-maintenance/#modeling-techniques","text":"The model uses the generated data from above scenarios: When the container's door is open for a longer time - this gives a false positive that maintainence is required. When sensors are malfunctioning, it records arbitrary readings. When the readings are normal. We have currently trained our model on 3000 datapoints from the three scenarios above. There are different modeling approach to tackle predictive maintenance: regression model classification to predict failure for a given time period classify anomalous behavior: classes are not known in advance. Normal operation is known. compute probability of failure over time","title":"Modeling techniques"},{"location":"predictive-maintenance/#code-execution","text":"The simulator continuosly generates container metrics, publishes it to Kafka and run the predictMaintainence.ipynb to predict if maintainence is sought at this point in time.","title":"Code execution"},{"location":"predictive-maintenance/#model-description","text":"We are using Machine Learning supervised learning here. There are two types of supervised learning - 1) Classification: Predict a categorical response, 2) Regression: Predict a continuous response","title":"Model description"},{"location":"predictive-maintenance/#linear-regression","text":"Pros: 1) Fast 2) No tuning required 3) Highly interpretable 4) Well-understood Cons: 1) Unlikely to produce the best predictive accuracy 2) Presumes a linear relationship between the features and response 3) If the relationship is highly non-linear as with many scenarios, linear relationship will not effectively model the relationship and its prediction would not be accurate","title":"Linear regression"},{"location":"predictive-maintenance/#naive-bayes-classification","text":"Naive Bayes is a probabilistic classifier inspired by the Bayes theorem under a simple assumption which is the attributes are conditionally independent. The classification is conducted by deriving the maximum posterior which is the maximal P(Ci|X) with the above assumption applying to Bayes theorem. This assumption greatly reduces the computational cost by only counting the class distribution. Even though the assumption is not valid in most cases since the attributes are dependent, surprisingly Naive Bayes has able to perform impressively. Naive Bayes is a very simple algorithm to implement and good results have obtained in most cases. It can be easily scalable to larger datasets since it takes linear time, rather than by expensive iterative approximation as used for many other types of classifiers. Naive Bayes can suffer from a problem called the zero probability problem. When the conditional probability is zero for a particular attribute, it fails to give a valid prediction. This needs to be fixed explicitly using a Laplacian estimator.","title":"Naive Bayes classification"},{"location":"predictive-maintenance/#model-evaluation","text":"We are using Root Mean Squared Error (RMSE) for evaluating the model performance. Root Mean Squared Error (RMSE) is the square root of the mean of the squared errors. Classification does better here as the scenarion is more of a classification problem.","title":"Model evaluation"},{"location":"predictive-maintenance/#references","text":"Understand Reefer container For modeling predictive maintenance we found this article from BigData Republique, on Medium, very interesting. PREDICTION OF TEMPERATURE INSIDE A REFRIGERATED CONTAINER IN THE PRESENCE OF PERISHABLE GOODS Temperature Monitoring During Transportation, Storage and Processing of Perishable Products Understanding machine learning classifiers","title":"References"}]}